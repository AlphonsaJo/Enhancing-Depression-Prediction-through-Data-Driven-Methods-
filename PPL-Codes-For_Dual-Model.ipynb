{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CNN + SVC with smote (2.3s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Training Time: 2.20 seconds\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Train Accuracy: 0.9401574803149606\n",
      "Test Accuracy: 0.9119496855345912\n",
      "Classification Report for Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92        91\n",
      "           1       0.88      0.93      0.90        68\n",
      "\n",
      "    accuracy                           0.91       159\n",
      "   macro avg       0.91      0.91      0.91       159\n",
      "weighted avg       0.91      0.91      0.91       159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Depression Dataset_With SMOTE.csv')\n",
    "\n",
    "# Preparing data: Features and Target\n",
    "X = df.drop('DEPRESSED', axis=1)\n",
    "y = df['DEPRESSED']\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshaping data for CNN input (adding a channel dimension)\n",
    "X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())  # Flattening the output to make it 2D\n",
    "cnn_model.add(Dense(units=64, activation='relu'))\n",
    "cnn_model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the CNN model\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure the start time for CNN training\n",
    "start_time_cnn = time.time()\n",
    "\n",
    "# Training the CNN model\n",
    "cnn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Measure the end time for CNN training\n",
    "end_time_cnn = time.time()\n",
    "\n",
    "# Calculate and print the CNN training time\n",
    "training_time_cnn = end_time_cnn - start_time_cnn\n",
    "print(f\"CNN Training Time: {training_time_cnn:.2f} seconds\")\n",
    "\n",
    "# Extracting features from CNN model\n",
    "cnn_features_train = cnn_model.predict(X_train)\n",
    "cnn_features_test = cnn_model.predict(X_test)\n",
    "\n",
    "# SVM Training and Testing\n",
    "svm_clf = SVC(kernel='linear')\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf.fit(cnn_features_train, y_train)\n",
    "\n",
    "# Predict using trained SVM classifier\n",
    "y_pred_svm_train = svm_clf.predict(cnn_features_train)\n",
    "y_pred_svm_test = svm_clf.predict(cnn_features_test)\n",
    "\n",
    "# Calculate train and test accuracies\n",
    "accuracy_train = accuracy_score(y_train, y_pred_svm_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_svm_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"Classification Report for Test Data:\")\n",
    "print(classification_report(y_test, y_pred_svm_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CNN + SVC without smote (2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Training Time: 1.83 seconds\n",
      "16/16 [==============================] - 0s 994us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Train Accuracy: 0.9192546583850931\n",
      "Test Accuracy: 0.9008264462809917\n",
      "Classification Report for Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88        44\n",
      "           1       0.97      0.87      0.92        77\n",
      "\n",
      "    accuracy                           0.90       121\n",
      "   macro avg       0.89      0.91      0.90       121\n",
      "weighted avg       0.91      0.90      0.90       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Depression Dataset_With Label Encoding.csv')\n",
    "\n",
    "# Preparing data: Features and Target\n",
    "X = df.drop('DEPRESSED', axis=1)\n",
    "y = df['DEPRESSED']\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshaping data for CNN input (adding a channel dimension)\n",
    "X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())  # Flattening the output to make it 2D\n",
    "cnn_model.add(Dense(units=64, activation='relu'))\n",
    "cnn_model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the CNN model\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure the start time for CNN training\n",
    "start_time_cnn = time.time()\n",
    "\n",
    "# Training the CNN model\n",
    "cnn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Measure the end time for CNN training\n",
    "end_time_cnn = time.time()\n",
    "\n",
    "# Calculate and print the CNN training time\n",
    "training_time_cnn = end_time_cnn - start_time_cnn\n",
    "print(f\"CNN Training Time: {training_time_cnn:.2f} seconds\")\n",
    "\n",
    "# Extracting features from CNN model\n",
    "cnn_features_train = cnn_model.predict(X_train)\n",
    "cnn_features_test = cnn_model.predict(X_test)\n",
    "\n",
    "# SVM Training and Testing\n",
    "svm_clf = SVC(kernel='linear')\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf.fit(cnn_features_train, y_train)\n",
    "\n",
    "# Predict using trained SVM classifier\n",
    "y_pred_svm_train = svm_clf.predict(cnn_features_train)\n",
    "y_pred_svm_test = svm_clf.predict(cnn_features_test)\n",
    "\n",
    "# Calculate train and test accuracies\n",
    "accuracy_train = accuracy_score(y_train, y_pred_svm_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_svm_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"Classification Report for Test Data:\")\n",
    "print(classification_report(y_test, y_pred_svm_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ANN + SVC with smote (1.7s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Training Time: 1.53 seconds\n",
      "20/20 [==============================] - 0s 787us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Train Accuracy: 0.9937007874015747\n",
      "Test Accuracy: 0.8930817610062893\n",
      "Classification Report for Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        91\n",
      "           1       0.85      0.91      0.88        68\n",
      "\n",
      "    accuracy                           0.89       159\n",
      "   macro avg       0.89      0.90      0.89       159\n",
      "weighted avg       0.90      0.89      0.89       159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Depression Dataset_With SMOTE.csv')\n",
    "\n",
    "# Preparing data: Features and Target\n",
    "X = df.drop('DEPRESSED', axis=1)\n",
    "y = df['DEPRESSED']\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building ANN model\n",
    "ann_model = Sequential()\n",
    "ann_model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "ann_model.add(Dense(units=64, activation='relu'))\n",
    "ann_model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the ANN model\n",
    "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure the start time for ANN training\n",
    "start_time_ann = time.time()\n",
    "\n",
    "# Training the ANN model\n",
    "ann_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Measure the end time for ANN training\n",
    "end_time_ann = time.time()\n",
    "\n",
    "# Calculate and print the ANN training time\n",
    "training_time_ann = end_time_ann - start_time_ann\n",
    "print(f\"ANN Training Time: {training_time_ann:.2f} seconds\")\n",
    "\n",
    "# Extracting features from ANN model\n",
    "ann_features_train = ann_model.predict(X_train)\n",
    "ann_features_test = ann_model.predict(X_test)\n",
    "\n",
    "# SVM Training and Testing\n",
    "svm_clf = SVC(kernel='linear')\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf.fit(ann_features_train, y_train)\n",
    "\n",
    "# Predict using trained SVM classifier\n",
    "y_pred_svm_train = svm_clf.predict(ann_features_train)\n",
    "y_pred_svm_test = svm_clf.predict(ann_features_test)\n",
    "\n",
    "# Calculate train and test accuracies\n",
    "accuracy_train = accuracy_score(y_train, y_pred_svm_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_svm_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"Classification Report for Test Data:\")\n",
    "print(classification_report(y_test, y_pred_svm_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ANN + SVC without smote (1.5s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Training Time: 1.30 seconds\n",
      "16/16 [==============================] - 0s 865us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Train Accuracy: 0.9813664596273292\n",
      "Test Accuracy: 0.8760330578512396\n",
      "Classification Report for Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84        44\n",
      "           1       0.94      0.86      0.90        77\n",
      "\n",
      "    accuracy                           0.88       121\n",
      "   macro avg       0.86      0.88      0.87       121\n",
      "weighted avg       0.89      0.88      0.88       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Depression Dataset_With Label Encoding.csv')\n",
    "\n",
    "# Preparing data: Features and Target\n",
    "X = df.drop('DEPRESSED', axis=1)\n",
    "y = df['DEPRESSED']\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building ANN model\n",
    "ann_model = Sequential()\n",
    "ann_model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "ann_model.add(Dense(units=64, activation='relu'))\n",
    "ann_model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the ANN model\n",
    "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure the start time for ANN training\n",
    "start_time_ann = time.time()\n",
    "\n",
    "# Training the ANN model\n",
    "ann_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Measure the end time for ANN training\n",
    "end_time_ann = time.time()\n",
    "\n",
    "# Calculate and print the ANN training time\n",
    "training_time_ann = end_time_ann - start_time_ann\n",
    "print(f\"ANN Training Time: {training_time_ann:.2f} seconds\")\n",
    "\n",
    "# Extracting features from ANN model\n",
    "ann_features_train = ann_model.predict(X_train)\n",
    "ann_features_test = ann_model.predict(X_test)\n",
    "\n",
    "# SVM Training and Testing\n",
    "svm_clf = SVC(kernel='linear')\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf.fit(ann_features_train, y_train)\n",
    "\n",
    "# Predict using trained SVM classifier\n",
    "y_pred_svm_train = svm_clf.predict(ann_features_train)\n",
    "y_pred_svm_test = svm_clf.predict(ann_features_test)\n",
    "\n",
    "# Calculate train and test accuracies\n",
    "accuracy_train = accuracy_score(y_train, y_pred_svm_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_svm_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"Classification Report for Test Data:\")\n",
    "print(classification_report(y_test, y_pred_svm_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. RBF + SVC (with SMOTE) 6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 6.07 seconds\n",
      "20/20 [==============================] - 0s 892us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Train Accuracy: 0.9212598425196851\n",
      "Test Accuracy: 0.89937106918239\n",
      "Classification Report for Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        91\n",
      "           1       0.85      0.93      0.89        68\n",
      "\n",
      "    accuracy                           0.90       159\n",
      "   macro avg       0.90      0.90      0.90       159\n",
      "weighted avg       0.90      0.90      0.90       159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer, Dense\n",
    "import keras.backend as K\n",
    "import time\n",
    "\n",
    "# Custom RBF layer\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.centers = self.add_weight(name='centers',\n",
    "                                       shape=(self.units, input_shape[1]),\n",
    "                                       initializer='uniform',\n",
    "                                       trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        C = K.expand_dims(self.centers)\n",
    "        H = K.transpose(C - K.transpose(inputs))\n",
    "        return K.exp(-self.gamma * K.sum(H**2, axis=1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Depression Dataset_With SMOTE.csv')\n",
    "\n",
    "# Preparing data: Features and Target\n",
    "X = df.drop('DEPRESSED', axis=1)\n",
    "y = df['DEPRESSED']\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building RBFN model\n",
    "model = Sequential()\n",
    "model.add(RBFLayer(units=10, gamma=0.5, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# Measure the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Extracting features using the RBFLayer\n",
    "rbf_features_train = model.predict(X_train)\n",
    "rbf_features_test = model.predict(X_test)\n",
    "\n",
    "# SVM Training and Testing\n",
    "svm_clf = SVC(kernel='rbf')\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf.fit(rbf_features_train, y_train)\n",
    "\n",
    "# Predict using trained SVM classifier\n",
    "y_pred_svm_train = svm_clf.predict(rbf_features_train)\n",
    "y_pred_svm_test = svm_clf.predict(rbf_features_test)\n",
    "\n",
    "# Calculate train and test accuracies\n",
    "accuracy_train = accuracy_score(y_train, y_pred_svm_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_svm_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"Classification Report for Test Data:\")\n",
    "print(classification_report(y_test, y_pred_svm_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. RBF + SVC without SMOTE 4.63s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 4.91 seconds\n",
      "16/16 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Train Accuracy: 0.8902691511387164\n",
      "Test Accuracy: 0.8925619834710744\n",
      "Classification Report for Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85        44\n",
      "           1       0.90      0.94      0.92        77\n",
      "\n",
      "    accuracy                           0.89       121\n",
      "   macro avg       0.89      0.88      0.88       121\n",
      "weighted avg       0.89      0.89      0.89       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer, Dense\n",
    "import keras.backend as K\n",
    "import time\n",
    "\n",
    "# Custom RBF layer\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.centers = self.add_weight(name='centers',\n",
    "                                       shape=(self.units, input_shape[1]),\n",
    "                                       initializer='uniform',\n",
    "                                       trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        C = K.expand_dims(self.centers)\n",
    "        H = K.transpose(C - K.transpose(inputs))\n",
    "        return K.exp(-self.gamma * K.sum(H**2, axis=1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Depression Dataset_With Label Encoding.csv')\n",
    "\n",
    "# Preparing data: Features and Target\n",
    "X = df.drop('DEPRESSED', axis=1)\n",
    "y = df['DEPRESSED']\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building RBFN model\n",
    "model = Sequential()\n",
    "model.add(RBFLayer(units=10, gamma=0.5, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# Measure the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Extracting features using the RBFLayer\n",
    "rbf_features_train = model.predict(X_train)\n",
    "rbf_features_test = model.predict(X_test)\n",
    "\n",
    "# SVM Training and Testing\n",
    "svm_clf = SVC(kernel='rbf')\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf.fit(rbf_features_train, y_train)\n",
    "\n",
    "# Predict using trained SVM classifier\n",
    "y_pred_svm_train = svm_clf.predict(rbf_features_train)\n",
    "y_pred_svm_test = svm_clf.predict(rbf_features_test)\n",
    "\n",
    "# Calculate train and test accuracies\n",
    "accuracy_train = accuracy_score(y_train, y_pred_svm_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_svm_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"Classification Report for Test Data:\")\n",
    "print(classification_report(y_test, y_pred_svm_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF + SVC with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 4.63 seconds\n",
      "16/16 [==============================] - 0s 879us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "Train Accuracy: 0.8944099378881988\n",
      "Test Accuracy: 0.9090909090909091\n",
      "Classification Report for Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87        44\n",
      "           1       0.92      0.94      0.93        77\n",
      "\n",
      "    accuracy                           0.91       121\n",
      "   macro avg       0.90      0.90      0.90       121\n",
      "weighted avg       0.91      0.91      0.91       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer, Dense\n",
    "import keras.backend as K\n",
    "import time\n",
    "\n",
    "# Custom RBF layer\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.centers = self.add_weight(name='centers',\n",
    "                                       shape=(self.units, input_shape[1]),\n",
    "                                       initializer='uniform',\n",
    "                                       trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        C = K.expand_dims(self.centers)\n",
    "        H = K.transpose(C - K.transpose(inputs))\n",
    "        return K.exp(-self.gamma * K.sum(H**2, axis=1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Depression Dataset_With Label Encoding.csv')\n",
    "\n",
    "# Preparing data: Features and Target\n",
    "X = df.drop('DEPRESSED', axis=1)\n",
    "y = df['DEPRESSED']\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building RBFN model\n",
    "model = Sequential()\n",
    "model.add(RBFLayer(units=10, gamma=0.5, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# Measure the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Extracting features using the RBFLayer\n",
    "rbf_features_train = model.predict(X_train)\n",
    "rbf_features_test = model.predict(X_test)\n",
    "\n",
    "# SVM Training and Testing\n",
    "svm_clf = SVC(kernel='rbf')\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf.fit(rbf_features_train, y_train)\n",
    "\n",
    "# Predict using trained SVM classifier\n",
    "y_pred_svm_train = svm_clf.predict(rbf_features_train)\n",
    "y_pred_svm_test = svm_clf.predict(rbf_features_test)\n",
    "\n",
    "# Calculate train and test accuracies\n",
    "accuracy_train = accuracy_score(y_train, y_pred_svm_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_svm_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_train)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# Classification report for test data\n",
    "print(\"Classification Report for Test Data:\")\n",
    "print(classification_report(y_test, y_pred_svm_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN + SVM + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "CNN Training Time: 1.54 seconds\n",
      "10/10 [==============================] - 0s 871us/step\n",
      "10/10 [==============================] - 0s 993us/step\n",
      "ANN Training Time: 1.11 seconds\n",
      "SVM Testing Accuracy: 0.9056603773584906\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       151\n",
      "           1       0.93      0.89      0.91       167\n",
      "\n",
      "    accuracy                           0.91       318\n",
      "   macro avg       0.91      0.91      0.91       318\n",
      "weighted avg       0.91      0.91      0.91       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Depression Dataset_With SMOTE.csv')\n",
    "\n",
    "# Preparing data: Features and Target\n",
    "X = df.drop('DEPRESSED', axis=1)\n",
    "y = df['DEPRESSED']\n",
    "\n",
    "# Scaling features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Adjust the train-test split ratio for the CNN or the ANN\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "X_train_ann, X_test_ann, y_train_ann, y_test_ann = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "# Building CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# Compiling the CNN model\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure the start time for CNN training\n",
    "start_time_cnn = time.time()\n",
    "\n",
    "# Training the CNN model\n",
    "cnn_model.fit(X_train_cnn.reshape(X_train_cnn.shape[0], X_train_cnn.shape[1], 1), y_train_cnn, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Extracting features from CNN\n",
    "X_train_features_cnn = cnn_model.predict(X_train_cnn.reshape(X_train_cnn.shape[0], X_train_cnn.shape[1], 1))\n",
    "X_test_features_cnn = cnn_model.predict(X_test_cnn.reshape(X_test_cnn.shape[0], X_test_cnn.shape[1], 1))\n",
    "\n",
    "# Measure the end time for CNN training\n",
    "end_time_cnn = time.time()\n",
    "\n",
    "# Calculate and print the CNN training time\n",
    "training_time_cnn = end_time_cnn - start_time_cnn\n",
    "print(f\"CNN Training Time: {training_time_cnn:.2f} seconds\")\n",
    "\n",
    "# Building ANN model\n",
    "ann_model = Sequential()\n",
    "ann_model.add(Dense(units=64, activation='relu', input_shape=(X_train_ann.shape[1],)))\n",
    "ann_model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# Compiling the ANN model\n",
    "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure the start time for ANN training\n",
    "start_time_ann = time.time()\n",
    "\n",
    "# Training the ANN model\n",
    "ann_model.fit(X_train_ann, y_train_ann, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Extracting features from ANN\n",
    "X_train_features_ann = ann_model.predict(X_train_ann)\n",
    "X_test_features_ann = ann_model.predict(X_test_ann)\n",
    "\n",
    "# Measure the end time for ANN training\n",
    "end_time_ann = time.time()\n",
    "\n",
    "# Calculate and print the ANN training time\n",
    "training_time_ann = end_time_ann - start_time_ann\n",
    "print(f\"ANN Training Time: {training_time_ann:.2f} seconds\")\n",
    "\n",
    "# Combine features from CNN and ANN\n",
    "X_train_features_combined = np.concatenate((X_train_features_cnn, X_train_features_ann), axis=1)\n",
    "X_test_features_combined = np.concatenate((X_test_features_cnn, X_test_features_ann), axis=1)\n",
    "\n",
    "# SVM Training and Testing\n",
    "svm_clf = SVC(kernel='linear')\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf.fit(X_train_features_combined, y_train_cnn)\n",
    "\n",
    "# Predict using trained SVM classifier\n",
    "y_pred_svm = svm_clf.predict(X_test_features_combined)\n",
    "\n",
    "# Evaluate SVM performance\n",
    "accuracy_svm = accuracy_score(y_test_cnn, y_pred_svm)\n",
    "print(\"SVM Testing Accuracy:\", accuracy_svm)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report for SVM:\")\n",
    "print(classification_report(y_test_cnn, y_pred_svm))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
